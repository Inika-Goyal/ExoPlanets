{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a41541ff-76dc-4789-856b-5e672bb2f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be157776-bb24-4c99-b058-c5194ab43902",
   "metadata": {},
   "outputs": [],
   "source": [
    "kepler = pd.read_csv(\"kepler_data.csv\", comment=\"#\")\n",
    "k2 = pd.read_csv(\"k2_data.csv\", comment=\"#\")\n",
    "tess = pd.read_csv(\"tess_data.csv\", comment = \"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5acabec-9e3e-4997-8458-cae7134b84ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset sizes:\n",
      "Kepler: 9564 rows\n",
      "K2: 4004 rows\n",
      "TESS: 7703 rows\n",
      "\n",
      "Warning (K2): Missing columns: {'pl_trandur', 'pl_trandep'}\n",
      "\n",
      "Combined dataset size: 21271 rows\n",
      "\n",
      "Column list: ['orbital_period', 'planet_radius', 'transit_duration', 'transit_depth', 'equilibrium_temp', 'insolation_flux', 'stellar_teff', 'stellar_radius', 'stellar_logg', 'disposition', 'survey']\n",
      "\n",
      "=== Missing Values Summary ===\n",
      "                  Missing Count  Percentage\n",
      "orbital_period              174        0.82\n",
      "planet_radius              1714        8.06\n",
      "transit_duration           4004       18.82\n",
      "transit_depth              4367       20.53\n",
      "equilibrium_temp           3833       18.02\n",
      "insolation_flux            3872       18.20\n",
      "stellar_teff               1651        7.76\n",
      "stellar_radius             1018        4.79\n",
      "stellar_logg               2876       13.52\n",
      "\n",
      "=== Disposition Distribution ===\n",
      "disposition\n",
      "CANDIDATE         8032\n",
      "FALSE POSITIVE    6351\n",
      "CONFIRMED         6328\n",
      "APC                462\n",
      "FA                  98\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Disposition by Survey ===\n",
      "disposition  APC  CANDIDATE  CONFIRMED  FA  FALSE POSITIVE    All\n",
      "survey                                                           \n",
      "K2             0       1374       2315   0             315   4004\n",
      "Kepler         0       1979       2746   0            4839   9564\n",
      "TESS         462       4679       1267  98            1197   7703\n",
      "All          462       8032       6328  98            6351  21271\n",
      "\n",
      "Rows before removing missing disposition: 21271\n",
      "Rows after removing missing disposition: 21271\n",
      "\n",
      "=== Feature Statistics ===\n",
      "       orbital_period  planet_radius  transit_duration  transit_depth  \\\n",
      "count    21097.000000   19557.000000      17267.000000   1.690400e+04   \n",
      "mean        48.245140      53.572028          4.478497   1.671233e+04   \n",
      "std       1072.414359    2111.472020          5.136641   6.229679e+04   \n",
      "min          0.152076       0.080000          0.052000   0.000000e+00   \n",
      "25%          2.627764       1.900000          2.122698   3.210000e+02   \n",
      "50%          5.836510       3.960000          3.214000   1.238500e+03   \n",
      "75%         16.303675      13.388600          4.892500   7.630000e+03   \n",
      "max     129995.778400  200346.000000        138.540000   1.541400e+06   \n",
      "\n",
      "       equilibrium_temp  insolation_flux  stellar_teff  stellar_radius  \\\n",
      "count      17438.000000     1.739900e+04  19620.000000    20253.000000   \n",
      "mean        1160.213458     5.100439e+03   5654.886018        1.508126   \n",
      "std          780.329786     1.162914e+05   1188.714217        4.371945   \n",
      "min           25.000000     0.000000e+00   2520.000000        0.109000   \n",
      "25%          647.000000     3.810500e+01   5171.000000        0.814000   \n",
      "50%         1008.000000     2.226070e+02   5718.000000        1.028000   \n",
      "75%         1488.750000     1.001955e+03   6131.475000        1.471000   \n",
      "max        14667.000000     1.094755e+07  50000.000000      229.908000   \n",
      "\n",
      "       stellar_logg  \n",
      "count  18395.000000  \n",
      "mean       4.324377  \n",
      "std        0.378180  \n",
      "min        0.047000  \n",
      "25%        4.180000  \n",
      "50%        4.411000  \n",
      "75%        4.540450  \n",
      "max        5.960650  \n",
      "\n",
      "✓ Saved processed data to 'combined_exoplanet_data.csv'\n",
      "\n",
      "Complete cases (no missing features): 15829 rows\n",
      "✓ Saved complete cases to 'combined_exoplanet_data_complete.csv'\n",
      "\n",
      "=== Class Balance in Complete Dataset ===\n",
      "disposition\n",
      "CANDIDATE         5898\n",
      "FALSE POSITIVE    5531\n",
      "CONFIRMED         3971\n",
      "APC                363\n",
      "FA                  66\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proportions:\n",
      "disposition\n",
      "CANDIDATE         0.373\n",
      "FALSE POSITIVE    0.349\n",
      "CONFIRMED         0.251\n",
      "APC               0.023\n",
      "FA                0.004\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "=== Final Training Dataset ===\n",
      "Total rows: 15400\n",
      "\n",
      "Class Distribution:\n",
      "disposition\n",
      "CANDIDATE         5898\n",
      "FALSE POSITIVE    5531\n",
      "CONFIRMED         3971\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Proportions:\n",
      "disposition\n",
      "CANDIDATE         0.383\n",
      "FALSE POSITIVE    0.359\n",
      "CONFIRMED         0.258\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "By Survey:\n",
      "disposition  CANDIDATE  CONFIRMED  FALSE POSITIVE    All\n",
      "survey                                                  \n",
      "Kepler            1875       2744            4582   9201\n",
      "TESS              4023       1227             949   6199\n",
      "All               5898       3971            5531  15400\n",
      "\n",
      "✓ Saved final training data to 'exoplanet_training_data.csv'\n"
     ]
    }
   ],
   "source": [
    "print(\"Original dataset sizes:\")\n",
    "print(f\"Kepler: {len(kepler)} rows\")\n",
    "print(f\"K2: {len(k2)} rows\")\n",
    "print(f\"TESS: {len(tess)} rows\")\n",
    "\n",
    "# Define column mappings for each dataset\n",
    "kepler_mapping = {\n",
    "    'koi_period': 'orbital_period',\n",
    "    'koi_prad': 'planet_radius',\n",
    "    'koi_duration': 'transit_duration',\n",
    "    'koi_depth': 'transit_depth',\n",
    "    'koi_teq': 'equilibrium_temp',\n",
    "    'koi_insol': 'insolation_flux',\n",
    "    'koi_steff': 'stellar_teff',\n",
    "    'koi_srad': 'stellar_radius',\n",
    "    'koi_slogg': 'stellar_logg',\n",
    "    'koi_disposition': 'disposition'\n",
    "}\n",
    "\n",
    "k2_mapping = {\n",
    "    'pl_orbper': 'orbital_period',\n",
    "    'pl_rade': 'planet_radius',\n",
    "    'pl_trandur': 'transit_duration',\n",
    "    'pl_trandep': 'transit_depth',\n",
    "    'pl_eqt': 'equilibrium_temp',\n",
    "    'pl_insol': 'insolation_flux',\n",
    "    'st_teff': 'stellar_teff',\n",
    "    'st_rad': 'stellar_radius',\n",
    "    'st_logg': 'stellar_logg',\n",
    "    'disposition': 'disposition'\n",
    "}\n",
    "\n",
    "tess_mapping = {\n",
    "    'pl_orbper': 'orbital_period',\n",
    "    'pl_rade': 'planet_radius',\n",
    "    'pl_trandurh': 'transit_duration',\n",
    "    'pl_trandep': 'transit_depth',\n",
    "    'pl_eqt': 'equilibrium_temp',\n",
    "    'pl_insol': 'insolation_flux',\n",
    "    'st_teff': 'stellar_teff',\n",
    "    'st_rad': 'stellar_radius',\n",
    "    'st_logg': 'stellar_logg',\n",
    "    'tfopwg_disp': 'disposition'\n",
    "}\n",
    "\n",
    "def preprocess_dataset(df, column_mapping, survey_name):\n",
    "    \"\"\"\n",
    "    Preprocess a single dataset by selecting and renaming columns.\n",
    "    \"\"\"\n",
    "    # Select only columns that exist in the dataframe\n",
    "    available_cols = {k: v for k, v in column_mapping.items() if k in df.columns}\n",
    "    \n",
    "    if len(available_cols) < len(column_mapping):\n",
    "        missing = set(column_mapping.keys()) - set(available_cols.keys())\n",
    "        print(f\"\\nWarning ({survey_name}): Missing columns: {missing}\")\n",
    "    \n",
    "    # Select and rename columns\n",
    "    df_processed = df[list(available_cols.keys())].copy()\n",
    "    df_processed = df_processed.rename(columns=available_cols)\n",
    "    \n",
    "    # Add survey identifier\n",
    "    df_processed['survey'] = survey_name\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# Preprocess each dataset\n",
    "kepler_processed = preprocess_dataset(kepler, kepler_mapping, 'Kepler')\n",
    "k2_processed = preprocess_dataset(k2, k2_mapping, 'K2')\n",
    "tess_processed = preprocess_dataset(tess, tess_mapping, 'TESS')\n",
    "\n",
    "# CRITICAL: Convert K2 transit depth from percentage to ppm\n",
    "# K2 uses %, others use ppm. 1% = 10,000 ppm\n",
    "if 'transit_depth' in k2_processed.columns:\n",
    "    print(\"\\nConverting K2 transit depth from % to ppm...\")\n",
    "    k2_processed['transit_depth'] = k2_processed['transit_depth'] * 10000\n",
    "\n",
    "# Standardize disposition labels\n",
    "def standardize_disposition(disposition):\n",
    "    \"\"\"\n",
    "    Standardize disposition labels across datasets.\n",
    "    \"\"\"\n",
    "    if pd.isna(disposition):\n",
    "        return np.nan\n",
    "    \n",
    "    disposition = str(disposition).upper().strip()\n",
    "    \n",
    "    # Map to standard labels\n",
    "    if 'CONFIRMED' in disposition or disposition == 'CP':\n",
    "        return 'CONFIRMED'\n",
    "    elif 'CANDIDATE' in disposition or disposition == 'PC':\n",
    "        return 'CANDIDATE'\n",
    "    elif 'FALSE' in disposition or disposition == 'FP':\n",
    "        return 'FALSE POSITIVE'\n",
    "    elif 'REFUTED' in disposition:\n",
    "        return 'FALSE POSITIVE'  # Treat refuted as false positive\n",
    "    elif disposition == 'KP':\n",
    "        return 'CONFIRMED'  # Known planet\n",
    "    else:\n",
    "        return disposition\n",
    "\n",
    "# Apply disposition standardization\n",
    "for df in [kepler_processed, k2_processed, tess_processed]:\n",
    "    if 'disposition' in df.columns:\n",
    "        df['disposition'] = df['disposition'].apply(standardize_disposition)\n",
    "\n",
    "# Combine all datasets\n",
    "combined_data = pd.concat([kepler_processed, k2_processed, tess_processed], \n",
    "                          ignore_index=True)\n",
    "\n",
    "print(f\"\\nCombined dataset size: {len(combined_data)} rows\")\n",
    "print(f\"\\nColumn list: {list(combined_data.columns)}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n=== Missing Values Summary ===\")\n",
    "missing_summary = combined_data.isnull().sum()\n",
    "missing_pct = (missing_summary / len(combined_data) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_summary,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "# Disposition distribution\n",
    "print(\"\\n=== Disposition Distribution ===\")\n",
    "print(combined_data['disposition'].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\n=== Disposition by Survey ===\")\n",
    "print(pd.crosstab(combined_data['survey'], combined_data['disposition'], \n",
    "                  margins=True, dropna=False))\n",
    "\n",
    "# Remove rows with missing disposition (can't train without labels)\n",
    "print(f\"\\nRows before removing missing disposition: {len(combined_data)}\")\n",
    "combined_data_clean = combined_data.dropna(subset=['disposition'])\n",
    "print(f\"Rows after removing missing disposition: {len(combined_data_clean)}\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\n=== Feature Statistics ===\")\n",
    "numeric_cols = ['orbital_period', 'planet_radius', 'transit_duration', \n",
    "                'transit_depth', 'equilibrium_temp', 'insolation_flux',\n",
    "                'stellar_teff', 'stellar_radius', 'stellar_logg']\n",
    "print(combined_data_clean[numeric_cols].describe())\n",
    "\n",
    "# Save processed data\n",
    "combined_data_clean.to_csv(\"combined_exoplanet_data.csv\", index=False)\n",
    "print(\"\\n✓ Saved processed data to 'combined_exoplanet_data.csv'\")\n",
    "\n",
    "# Optional: Create a version with no missing values in features\n",
    "combined_data_complete = combined_data_clean.dropna(subset=numeric_cols)\n",
    "print(f\"\\nComplete cases (no missing features): {len(combined_data_complete)} rows\")\n",
    "combined_data_complete.to_csv(\"combined_exoplanet_data_complete.csv\", index=False)\n",
    "print(\"✓ Saved complete cases to 'combined_exoplanet_data_complete.csv'\")\n",
    "\n",
    "# Summary statistics by disposition\n",
    "print(\"\\n=== Class Balance in Complete Dataset ===\")\n",
    "print(combined_data_complete['disposition'].value_counts())\n",
    "print(\"\\nProportions:\")\n",
    "print(combined_data_complete['disposition'].value_counts(normalize=True).round(3))\n",
    "\n",
    "# Filter to only valid classes for training\n",
    "valid_dispositions = ['CANDIDATE', 'FALSE POSITIVE', 'CONFIRMED']\n",
    "combined_data_final = combined_data_complete[\n",
    "    combined_data_complete['disposition'].isin(valid_dispositions)\n",
    "].copy()\n",
    "\n",
    "print(f\"\\n=== Final Training Dataset ===\")\n",
    "print(f\"Total rows: {len(combined_data_final)}\")\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(combined_data_final['disposition'].value_counts())\n",
    "print(\"\\nClass Proportions:\")\n",
    "print(combined_data_final['disposition'].value_counts(normalize=True).round(3))\n",
    "\n",
    "print(\"\\nBy Survey:\")\n",
    "print(pd.crosstab(combined_data_final['survey'], \n",
    "                  combined_data_final['disposition'], \n",
    "                  margins=True))\n",
    "\n",
    "# Save final training dataset\n",
    "combined_data_final.to_csv(\"exoplanet_training_data.csv\", index=False)\n",
    "print(\"\\n✓ Saved final training data to 'exoplanet_training_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f45f1a8-f2d1-4982-9e6b-722320ebd6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Original Dataset ===\n",
      "Total samples: 15829\n",
      "\n",
      "Disposition distribution:\n",
      "disposition\n",
      "CANDIDATE         5898\n",
      "FALSE POSITIVE    5531\n",
      "CONFIRMED         3971\n",
      "APC                363\n",
      "FA                  66\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Data Split ===\n",
      "Labeled data (for training/testing): 9502\n",
      "  - CONFIRMED: 3971\n",
      "  - FALSE POSITIVE: 5531\n",
      "\n",
      "Candidate data (for prediction): 5898\n",
      "\n",
      "=== Labeled Data by Survey ===\n",
      "disposition  CONFIRMED  FALSE POSITIVE   All\n",
      "survey                                      \n",
      "Kepler            2744            4582  7326\n",
      "TESS              1227             949  2176\n",
      "All               3971            5531  9502\n",
      "\n",
      "=== Candidate Data by Survey ===\n",
      "survey\n",
      "TESS      4023\n",
      "Kepler    1875\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Binary Classification Task ===\n",
      "Target: 1 = CONFIRMED planet, 0 = FALSE POSITIVE\n",
      "Class balance: 0.418 positive (CONFIRMED)\n",
      "\n",
      "=== Train/Test Split ===\n",
      "Training set: 7126 samples (75.0%)\n",
      "  - CONFIRMED: 2978 (41.8%)\n",
      "  - FALSE POSITIVE: 4148 (58.2%)\n",
      "\n",
      "Test set: 2376 samples (25.0%)\n",
      "  - CONFIRMED: 993 (41.8%)\n",
      "  - FALSE POSITIVE: 1383 (58.2%)\n",
      "\n",
      "=== Candidate Pool (Lost Exoplanets) ===\n",
      "Total candidates to classify: 5898\n",
      "These will be used for final predictions after model is trained\n",
      "\n",
      "=== Files Saved ===\n",
      "Training/Testing (use these to build your model):\n",
      "  ✓ train_labeled.csv / train_labeled_scaled.csv\n",
      "  ✓ test_labeled.csv / test_labeled_scaled.csv\n",
      "\n",
      "Prediction (use these to find lost exoplanets):\n",
      "  ✓ candidates_unlabeled.csv / candidates_unlabeled_scaled.csv\n",
      "\n",
      "Scaler:\n",
      "  ✓ feature_scaler.pkl\n",
      "\n",
      "=== Feature Statistics (Training Set) ===\n",
      "       orbital_period  planet_radius  transit_duration  transit_depth  \\\n",
      "count     7126.000000    7126.000000       7126.000000   7.126000e+03   \n",
      "mean        41.327291      91.158288          5.092661   2.348437e+04   \n",
      "std        104.379744    3169.636188          6.049279   7.789890e+04   \n",
      "min          0.163821       0.080000          0.104600   8.000000e-01   \n",
      "25%          2.215970       1.710000          2.302550   2.479250e+02   \n",
      "50%          5.910374       3.290000          3.465000   7.600000e+02   \n",
      "75%         20.499226      16.903675          5.489950   6.043225e+03   \n",
      "max       1825.048364  200346.000000        117.520000   1.541400e+06   \n",
      "\n",
      "       equilibrium_temp  insolation_flux  stellar_teff  stellar_radius  \\\n",
      "count       7126.000000     7.126000e+03   7126.000000     7126.000000   \n",
      "mean        1207.719403     6.639223e+03   5725.026274        1.640183   \n",
      "std          883.228277     1.052727e+05   1042.159861        5.458279   \n",
      "min          103.000000     1.872750e-02   2661.000000        0.114827   \n",
      "25%          622.000000     3.452750e+01   5284.000000        0.830000   \n",
      "50%         1001.878223     2.285115e+02   5780.000000        1.016000   \n",
      "75%         1556.000000     1.254835e+03   6151.000000        1.449000   \n",
      "max        13184.000000     7.165673e+06  31000.000000      229.908000   \n",
      "\n",
      "       stellar_logg  \n",
      "count   7126.000000  \n",
      "mean       4.313227  \n",
      "std        0.416578  \n",
      "min        0.047000  \n",
      "25%        4.186000  \n",
      "50%        4.428000  \n",
      "75%        4.540000  \n",
      "max        5.960650  \n",
      "\n",
      "=== Workflow Summary ===\n",
      "1. Train your model on train_labeled*.csv\n",
      "2. Evaluate performance on test_labeled*.csv\n",
      "3. Tune hyperparameters using cross-validation on training data\n",
      "4. Once satisfied, predict on candidates_unlabeled*.csv\n",
      "5. Candidates with high confidence scores = potential lost exoplanets!\n",
      "\n",
      "=== Candidate Distribution ===\n",
      "survey\n",
      "TESS      4023\n",
      "Kepler    1875\n",
      "Name: count, dtype: int64\n",
      "\n",
      "That's 5898 potential exoplanets to discover!\n"
     ]
    }
   ],
   "source": [
    "# Load the combined data\n",
    "data = pd.read_csv(\"combined_exoplanet_data_complete.csv\")\n",
    "\n",
    "print(\"=== Original Dataset ===\")\n",
    "print(f\"Total samples: {len(data)}\")\n",
    "print(\"\\nDisposition distribution:\")\n",
    "print(data['disposition'].value_counts())\n",
    "\n",
    "# Separate into labeled (for training) and unlabeled (for prediction)\n",
    "# LABELED: Confirmed exoplanets and False Positives (we know ground truth)\n",
    "# UNLABELED: Candidates (the \"lost exoplanets\" we want to identify)\n",
    "\n",
    "labeled_classes = ['CONFIRMED', 'FALSE POSITIVE']\n",
    "labeled_data = data[data['disposition'].isin(labeled_classes)].copy()\n",
    "\n",
    "candidate_data = data[data['disposition'] == 'CANDIDATE'].copy()\n",
    "\n",
    "print(\"\\n=== Data Split ===\")\n",
    "print(f\"Labeled data (for training/testing): {len(labeled_data)}\")\n",
    "print(f\"  - CONFIRMED: {(labeled_data['disposition'] == 'CONFIRMED').sum()}\")\n",
    "print(f\"  - FALSE POSITIVE: {(labeled_data['disposition'] == 'FALSE POSITIVE').sum()}\")\n",
    "print(f\"\\nCandidate data (for prediction): {len(candidate_data)}\")\n",
    "\n",
    "print(\"\\n=== Labeled Data by Survey ===\")\n",
    "print(pd.crosstab(labeled_data['survey'], labeled_data['disposition'], margins=True))\n",
    "\n",
    "print(\"\\n=== Candidate Data by Survey ===\")\n",
    "print(candidate_data['survey'].value_counts())\n",
    "\n",
    "# Define features\n",
    "feature_cols = [\n",
    "    'orbital_period', \n",
    "    'planet_radius', \n",
    "    'transit_duration', \n",
    "    'transit_depth', \n",
    "    'equilibrium_temp', \n",
    "    'insolation_flux',\n",
    "    'stellar_teff', \n",
    "    'stellar_radius', \n",
    "    'stellar_logg'\n",
    "]\n",
    "\n",
    "# === LABELED DATA: Create train/test split ===\n",
    "X_labeled = labeled_data[feature_cols]\n",
    "y_labeled = labeled_data['disposition']\n",
    "survey_labeled = labeled_data['survey']\n",
    "\n",
    "# Create binary labels for classification\n",
    "# 1 = CONFIRMED (planet), 0 = FALSE POSITIVE (not a planet)\n",
    "y_binary = (y_labeled == 'CONFIRMED').astype(int)\n",
    "\n",
    "print(\"\\n=== Binary Classification Task ===\")\n",
    "print(\"Target: 1 = CONFIRMED planet, 0 = FALSE POSITIVE\")\n",
    "print(f\"Class balance: {y_binary.mean():.3f} positive (CONFIRMED)\")\n",
    "\n",
    "# Stratified split by both disposition and survey\n",
    "labeled_data['strata'] = labeled_data['disposition'] + '_' + labeled_data['survey']\n",
    "\n",
    "X_train, X_test, y_train, y_test, survey_train, survey_test = train_test_split(\n",
    "    X_labeled, y_binary, survey_labeled,\n",
    "    test_size=0.25,\n",
    "    random_state=67,\n",
    "    stratify=labeled_data['strata']\n",
    ")\n",
    "\n",
    "print(\"\\n=== Train/Test Split ===\")\n",
    "print(f\"Training set: {len(X_train)} samples ({len(X_train)/len(labeled_data)*100:.1f}%)\")\n",
    "print(f\"  - CONFIRMED: {y_train.sum()} ({y_train.mean()*100:.1f}%)\")\n",
    "print(f\"  - FALSE POSITIVE: {(1-y_train).sum()} ({(1-y_train.mean())*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTest set: {len(X_test)} samples ({len(X_test)/len(labeled_data)*100:.1f}%)\")\n",
    "print(f\"  - CONFIRMED: {y_test.sum()} ({y_test.mean()*100:.1f}%)\")\n",
    "print(f\"  - FALSE POSITIVE: {(1-y_test).sum()} ({(1-y_test.mean())*100:.1f}%)\")\n",
    "\n",
    "# === CANDIDATE DATA: Prepare for prediction ===\n",
    "X_candidates = candidate_data[feature_cols]\n",
    "\n",
    "print(\"\\n=== Candidate Pool (Lost Exoplanets) ===\")\n",
    "print(f\"Total candidates to classify: {len(X_candidates)}\")\n",
    "print(\"These will be used for final predictions after model is trained\")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train), \n",
    "    columns=feature_cols, \n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test), \n",
    "    columns=feature_cols, \n",
    "    index=X_test.index\n",
    ")\n",
    "X_candidates_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_candidates), \n",
    "    columns=feature_cols, \n",
    "    index=X_candidates.index\n",
    ")\n",
    "\n",
    "# Save datasets\n",
    "# 1. Training data (unscaled)\n",
    "train_df = X_train.copy()\n",
    "train_df['label'] = y_train.values\n",
    "train_df['survey'] = survey_train.values\n",
    "train_df.to_csv(\"train_labeled.csv\", index=False)\n",
    "\n",
    "# 2. Test data (unscaled)\n",
    "test_df = X_test.copy()\n",
    "test_df['label'] = y_test.values\n",
    "test_df['survey'] = survey_test.values\n",
    "test_df.to_csv(\"test_labeled.csv\", index=False)\n",
    "\n",
    "# 3. Training data (scaled)\n",
    "train_df_scaled = X_train_scaled.copy()\n",
    "train_df_scaled['label'] = y_train.values\n",
    "train_df_scaled['survey'] = survey_train.values\n",
    "train_df_scaled.to_csv(\"train_labeled_scaled.csv\", index=False)\n",
    "\n",
    "# 4. Test data (scaled)\n",
    "test_df_scaled = X_test_scaled.copy()\n",
    "test_df_scaled['label'] = y_test.values\n",
    "test_df_scaled['survey'] = survey_test.values\n",
    "test_df_scaled.to_csv(\"test_labeled_scaled.csv\", index=False)\n",
    "\n",
    "# 5. Candidate data (unscaled)\n",
    "candidates_df = X_candidates.copy()\n",
    "candidates_df['survey'] = candidate_data['survey'].values\n",
    "# Save some metadata for later reference\n",
    "candidates_df['original_index'] = candidate_data.index\n",
    "candidates_df.to_csv(\"candidates_unlabeled.csv\", index=False)\n",
    "\n",
    "# 6. Candidate data (scaled)\n",
    "candidates_df_scaled = X_candidates_scaled.copy()\n",
    "candidates_df_scaled['survey'] = candidate_data['survey'].values\n",
    "candidates_df_scaled['original_index'] = candidate_data.index\n",
    "candidates_df_scaled.to_csv(\"candidates_unlabeled_scaled.csv\", index=False)\n",
    "\n",
    "# 7. Save scaler for later use\n",
    "import joblib\n",
    "joblib.dump(scaler, 'feature_scaler.pkl')\n",
    "\n",
    "print(\"\\n=== Files Saved ===\")\n",
    "print(\"Training/Testing (use these to build your model):\")\n",
    "print(\"  ✓ train_labeled.csv / train_labeled_scaled.csv\")\n",
    "print(\"  ✓ test_labeled.csv / test_labeled_scaled.csv\")\n",
    "print(\"\\nPrediction (use these to find lost exoplanets):\")\n",
    "print(\"  ✓ candidates_unlabeled.csv / candidates_unlabeled_scaled.csv\")\n",
    "print(\"\\nScaler:\")\n",
    "print(\"  ✓ feature_scaler.pkl\")\n",
    "\n",
    "print(\"\\n=== Feature Statistics (Training Set) ===\")\n",
    "print(X_train.describe())\n",
    "\n",
    "print(\"\\n=== Workflow Summary ===\")\n",
    "print(\"1. Train your model on train_labeled*.csv\")\n",
    "print(\"2. Evaluate performance on test_labeled*.csv\")\n",
    "print(\"3. Tune hyperparameters using cross-validation on training data\")\n",
    "print(\"4. Once satisfied, predict on candidates_unlabeled*.csv\")\n",
    "print(\"5. Candidates with high confidence scores = potential lost exoplanets!\")\n",
    "\n",
    "# Additional insight: How many candidates per survey?\n",
    "print(\"\\n=== Candidate Distribution ===\")\n",
    "candidates_by_survey = candidate_data['survey'].value_counts()\n",
    "print(candidates_by_survey)\n",
    "print(f\"\\nThat's {len(candidate_data)} potential exoplanets to discover!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a60e8d8-8a21-4cd0-aad4-c4ac2fb38f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
